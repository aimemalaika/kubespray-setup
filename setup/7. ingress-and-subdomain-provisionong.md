# **Kubernetes HAProxy + NGINX Ingress Setup (Production-Ready with VIP & Wildcard DNS)**

## **Prerequisites**

* Bare-metal Kubernetes cluster with:

  * 3 Control Plane nodes (`192.168.10.171-173`)
  * 3 Worker nodes (`192.168.10.174-176`)
* HAProxy installed on a node with **VIP: 192.168.10.177**
* Wildcard DNS: `*.apps.brd-hq-cluster.brd.rw â†’ 192.168.10.177`
* `kubectl` configured and tested on control-plane nodes

---

## **Step 1: Deploy NGINX Ingress Controller**

1. Create namespace:

```bash
kubectl create namespace ingress-nginx
```

2. Deploy the bare-metal NGINX Ingress Controller:

```bash
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.1/deploy/static/provider/baremetal/deploy.yaml
```

3. Verify pods are running:

```bash
kubectl get pods -n ingress-nginx -w
```

Expected output:

```
ingress-nginx-controller-xxxx   1/1 Running
ingress-nginx-admission-xxxx   Completed
```

---

## **Step 2: Expose NGINX Ingress via NodePorts**

* Patch the Ingress service to NodePort (instead of ClusterIP):

```bash
kubectl -n ingress-nginx patch svc ingress-nginx-controller -p '{"spec":{"type":"NodePort"}}'
```

* Check assigned NodePorts:

```bash
kubectl -n ingress-nginx get svc ingress-nginx-controller
```

Example output:

```
80:30080/TCP, 443:30443/TCP
```

---

## **Step 3: Configure HAProxy**

* Update `/etc/haproxy/haproxy.cfg` with the following:

```haproxy
# =========================
# Ingress HTTPS (TLS passthrough)
# =========================
frontend https
    bind *:443
    mode tcp
    option tcplog
    default_backend ingress_https_backend

backend ingress_https_backend
    mode tcp
    balance roundrobin
    server worker1 192.168.10.174:30443 check
    server worker2 192.168.10.175:30443 check
    server worker3 192.168.10.176:30443 check

# =========================
# Ingress HTTP
# =========================
frontend http
    bind *:80
    mode http
    option httplog
    default_backend ingress_http_backend

backend ingress_http_backend
    mode http
    balance roundrobin
    option httpchk GET /
    server worker1 192.168.10.174:30080 check
    server worker2 192.168.10.175:30080 check
    server worker3 192.168.10.176:30080 check

# =========================
# HAProxy stats (optional)
# =========================
listen stats
    bind *:8404
    stats enable
    stats uri /haproxy?stats
    stats refresh 10s
```

---

## **Step 4: Reload HAProxy**

```bash
sudo haproxy -c -f /etc/haproxy/haproxy.cfg   # Check syntax
sudo systemctl restart haproxy
```

---

## **Step 5: Test Access**

1. **Kubernetes API via VIP**:

```bash
kubectl --server=https://192.168.10.177:8443 get nodes
```

2. **Ingress services via wildcard DNS**:

```bash
curl -v http://myservice.apps.brd-hq-cluster.brd.rw
curl -vk https://myservice.apps.brd-hq-cluster.brd.rw
```

* HTTP may return `503` until an Ingress rule exists.
* HTTPS shows self-signed certificate until you deploy a proper TLS secret.

---

## **Step 6: Create Ingress for your services**

Example:

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myservice-ingress
  namespace: default
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: myservice.apps.brd-hq-cluster.brd.rw
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: myservice
            port:
              number: 80
```

* Apply: `kubectl apply -f myservice-ingress.yaml`
* Access: `https://myservice.apps.brd-hq-cluster.brd.rw`

---

## **Notes & Tips**

* **TLS**: Replace the self-signed Ingress certificate with a real one (via Cert-Manager or manually).
* **Scaling**: Add more worker nodes and NodePorts in HAProxy backend as needed.
* **Dynamic pods**: Pod IPs change; using NodePorts avoids updating HAProxy constantly.
* **VIP + wildcard DNS**: Makes all services accessible under `*.apps.brd-hq-cluster.brd.rw`.

---
